{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elicit Basics\n",
    "\n",
    "This example will walk you through the basics of how to:\n",
    "- Create an \"Extractor\", a controller which handles the extraction.\n",
    "- Add required labelling functions and schemas to the extractor.\n",
    "- Run the extraction process.\n",
    "- Launch the user interface to begin annotating the extractions.\n",
    "\n",
    "We will be using the existing Keyword Extractor labelling function as an example.\n",
    "\n",
    "We begin by importing the requirements.\n",
    "\n",
    "## Importing Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/dev/Turing/elicit/examples\n",
      "Documents: ['doc_1.txt', 'doc_2.txt']\n"
     ]
    }
   ],
   "source": [
    "# Import Extractor class and launch UI function.\n",
    "from elicit import Extractor, launch_ui\n",
    "# Import the Keyword Match Labelling Function.\n",
    "from elicit.generic_labelling_functions import KeywordMatchLF, SimilarityLabellingFunction, NLILabellingFunction, SemanticSearchLF\n",
    "# Import Pathlib, for better path handling.\n",
    "from pathlib import Path\n",
    "# Import OS so we know where the notebook is!\n",
    "import os\n",
    "\n",
    "current_path = os.path.abspath('')\n",
    "\n",
    "# get current directory\n",
    "current_dir = Path(current_path)\n",
    "\n",
    "docs = list((current_dir / \"basic_example_docs\").glob(\"*.txt\"))\n",
    "\n",
    "print(\"Current directory:\", current_dir)\n",
    "print(\"Documents:\", [d.name for d in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Extractor\n",
    "\n",
    "Lets first create an Extractor object, pointing at the DB file we want to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Extraction Database: /home/dev/Turing/elicit/examples/test_db.sqlite\n"
     ]
    }
   ],
   "source": [
    "# delete db if already exists (just for testing purposes)\n",
    "# (current_dir / \"test_db.sqlite\").unlink(missing_ok=True)\n",
    "\n",
    "extractor = Extractor(db_path=current_dir / \"test_db.sqlite\", model_path=current_dir / \"models\", device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering Schemas\n",
    "\n",
    "Next, we will add the required schemas. These are the configuration files the labelling functions will use to extract the data.\n",
    "\n",
    "In this case, we require:\n",
    "- A categories schema\n",
    "- A keywords schema\n",
    "\n",
    "Categories is always required. It tells the system what categories each variable has, or whether it is numerical/raw. More details on this in the documentation.\n",
    "\n",
    "Keywords are a dictionary of variable category to keyword list. Each category of a variable will have some user-defined set of keywords.\n",
    "\n",
    "These schemas can either be a Path to a yaml file, or a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered schema: categories\n",
      "Registered schema: keywords\n",
      "Registered schema: questions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categories = {\"cat_or_dog\": [\"cat\", \"dog\"]}\n",
    "keywords = {\"cat_or_dog\": {\"cat\": [\"meow\", \"hiss\"], \"dog\": [\"woof\", \"bark\"]}}\n",
    "questions = {\"cat_or_dog\": [\"Is this a cat?\", \"Is this a dog?\"]}\n",
    "\n",
    "extractor.register_schema(schema=categories,\n",
    "                            schema_name=\"categories\")\n",
    "extractor.register_schema(schema=keywords,\n",
    "                            schema_name=\"keywords\")#\n",
    "extractor.register_schema(schema=questions,\n",
    "                            schema_name=\"questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering Labelling Functions\n",
    "\n",
    "Next, we register the labelling function. In this case, we have just imported the pre-defined Keyword Extractor labelling function. In a future tutorial, we will create our own labelling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered labelling function: Q&A → NLI Transformer\n",
      "Registered labelling function: Q&A → Similarity Transformer\n",
      "Registered labelling function: Keyword Match\n",
      "Registered labelling function: Semantic Search\n"
     ]
    }
   ],
   "source": [
    "extractor.register_labelling_function(NLILabellingFunction)\n",
    "extractor.register_labelling_function(SimilarityLabellingFunction)\n",
    "extractor.register_labelling_function(KeywordMatchLF)\n",
    "extractor.register_labelling_function(SemanticSearchLF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the extractor\n",
    "\n",
    "We can now run the extraction process, we pass a list of Paths pointing to each document. Currently PDFs and TXTs are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LF: Q&A → NLI Transformer\n",
      "Loading Resources.\n",
      "Fine tuned Sequence Classifier model found, loading...\n",
      "Fine tuned Q&A model found, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'RobertaForQuestionAnsweringWithNegatives' is not supported for question-answering. Supported models are ['QDQBertForQuestionAnswering', 'FNetForQuestionAnswering', 'GPTJForQuestionAnswering', 'LayoutLMv2ForQuestionAnswering', 'RemBertForQuestionAnswering', 'CanineForQuestionAnswering', 'RoFormerForQuestionAnswering', 'BigBirdPegasusForQuestionAnswering', 'BigBirdForQuestionAnswering', 'ConvBertForQuestionAnswering', 'LEDForQuestionAnswering', 'DistilBertForQuestionAnswering', 'AlbertForQuestionAnswering', 'CamembertForQuestionAnswering', 'BartForQuestionAnswering', 'MBartForQuestionAnswering', 'LongformerForQuestionAnswering', 'XLMRobertaForQuestionAnswering', 'RobertaForQuestionAnswering', 'SqueezeBertForQuestionAnswering', 'BertForQuestionAnswering', 'XLNetForQuestionAnsweringSimple', 'FlaubertForQuestionAnsweringSimple', 'MegatronBertForQuestionAnswering', 'MobileBertForQuestionAnswering', 'XLMForQuestionAnsweringSimple', 'ElectraForQuestionAnswering', 'ReformerForQuestionAnswering', 'FunnelForQuestionAnswering', 'LxmertForQuestionAnswering', 'MPNetForQuestionAnswering', 'DebertaForQuestionAnswering', 'DebertaV2ForQuestionAnswering', 'IBertForQuestionAnswering', 'SplinterForQuestionAnswering'].\n",
      "Extracting variable: cat_or_dog: 100%|██████████| 2/2 [00:00<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LF: Q&A → Similarity Transformer\n",
      "Loading Resources.\n",
      "Fine tuning similarity model found, loading...\n",
      "Fine tuned Q&A model found, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'RobertaForQuestionAnsweringWithNegatives' is not supported for question-answering. Supported models are ['QDQBertForQuestionAnswering', 'FNetForQuestionAnswering', 'GPTJForQuestionAnswering', 'LayoutLMv2ForQuestionAnswering', 'RemBertForQuestionAnswering', 'CanineForQuestionAnswering', 'RoFormerForQuestionAnswering', 'BigBirdPegasusForQuestionAnswering', 'BigBirdForQuestionAnswering', 'ConvBertForQuestionAnswering', 'LEDForQuestionAnswering', 'DistilBertForQuestionAnswering', 'AlbertForQuestionAnswering', 'CamembertForQuestionAnswering', 'BartForQuestionAnswering', 'MBartForQuestionAnswering', 'LongformerForQuestionAnswering', 'XLMRobertaForQuestionAnswering', 'RobertaForQuestionAnswering', 'SqueezeBertForQuestionAnswering', 'BertForQuestionAnswering', 'XLNetForQuestionAnsweringSimple', 'FlaubertForQuestionAnsweringSimple', 'MegatronBertForQuestionAnswering', 'MobileBertForQuestionAnswering', 'XLMForQuestionAnsweringSimple', 'ElectraForQuestionAnswering', 'ReformerForQuestionAnswering', 'FunnelForQuestionAnswering', 'LxmertForQuestionAnswering', 'MPNetForQuestionAnswering', 'DebertaForQuestionAnswering', 'DebertaV2ForQuestionAnswering', 'IBertForQuestionAnswering', 'SplinterForQuestionAnswering'].\n",
      "Extracting variable: cat_or_dog: 100%|██████████| 2/2 [00:00<00:00, 10.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LF: Keyword Match\n",
      "Loading Resources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting variable: cat_or_dog: 100%|██████████| 2/2 [00:01<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LF: Semantic Search\n",
      "Loading Resources.\n",
      "Fine tuning similarity model found, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting variable: cat_or_dog: 100%|██████████| 2/2 [00:00<00:00,  8.19it/s]\n"
     ]
    }
   ],
   "source": [
    "extractor.run(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the user interface\n",
    "\n",
    "Finally, we can launch the user interface to begin annotating the extractions, pointing either to a database path, or simply passing in the extractor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Launched UI at: <a href=\"http://localhost:8080\">http://localhost:8080</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UI Killed\n"
     ]
    }
   ],
   "source": [
    "launch_ui(extractor=extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating confidence scores.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576665aa040d499ab7c4112a73a8d373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabef83ad9d64340a75edb10eadaaf21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def1f4c67c2e4a70b02985382f019239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c63ddbd37e94f00be249fa722384688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cat_or_dog': 0.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.sort(method=\"weasul\")\n",
    "extractor.performance(performance_type=\"confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/dev/Turing/elicit/database/db_utils.py\u001b[0m(37)\u001b[0;36mquery_db\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     35 \u001b[0;31m    \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     36 \u001b[0;31m    \"\"\"\n",
      "\u001b[0m\u001b[0;32m---> 37 \u001b[0;31m    \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     38 \u001b[0;31m    \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     39 \u001b[0;31m    \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/dev/Turing/elicit/user_interface/server/sorting.py\u001b[0m(13)\u001b[0;36mset_value_confidence\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     11 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mset_value_confidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 13 \u001b[0;31m    query_db(\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m        db, f\"UPDATE extraction SET value_confidence={'NULL' if confidence == '?' else confidence} WHERE variable_id={variable_id}\")\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m    \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "*** SyntaxError: unexpected EOF while parsing\n",
      "array([0.72447455, 0.22928038, 0.15103534, 0.22571978, 0.72412279,\n",
      "       0.15103534, 0.72447455, 0.72412279, 0.72447455, 0.72412279,\n",
      "       0.72447455, 0.72412279, 0.72447455, 0.72412279])\n",
      "0     0\n",
      "1     1\n",
      "2     2\n",
      "3     3\n",
      "4     4\n",
      "5     5\n",
      "6     0\n",
      "7     4\n",
      "8     0\n",
      "9     4\n",
      "10    0\n",
      "11    4\n",
      "12    0\n",
      "13    4\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once some extractions have been validated - labelling functions can be fine-tuned with `extractor.train()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Resources for LF: Keyword Match\n",
      "Training LF: Keyword Match on variable: cat_or_dog\n",
      "4 documents with validations for variable: cat_or_dog\n",
      "Loading Resources for LF: Q&A → Similarity Transformer\n",
      "No fine tuning similarity model found, loading default.\n",
      "Fine tuned Q&A model found, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'RobertaForQuestionAnsweringWithNegatives' is not supported for question-answering. Supported models are ['QDQBertForQuestionAnswering', 'FNetForQuestionAnswering', 'GPTJForQuestionAnswering', 'LayoutLMv2ForQuestionAnswering', 'RemBertForQuestionAnswering', 'CanineForQuestionAnswering', 'RoFormerForQuestionAnswering', 'BigBirdPegasusForQuestionAnswering', 'BigBirdForQuestionAnswering', 'ConvBertForQuestionAnswering', 'LEDForQuestionAnswering', 'DistilBertForQuestionAnswering', 'AlbertForQuestionAnswering', 'CamembertForQuestionAnswering', 'BartForQuestionAnswering', 'MBartForQuestionAnswering', 'LongformerForQuestionAnswering', 'XLMRobertaForQuestionAnswering', 'RobertaForQuestionAnswering', 'SqueezeBertForQuestionAnswering', 'BertForQuestionAnswering', 'XLNetForQuestionAnsweringSimple', 'FlaubertForQuestionAnsweringSimple', 'MegatronBertForQuestionAnswering', 'MobileBertForQuestionAnswering', 'XLMForQuestionAnsweringSimple', 'ElectraForQuestionAnswering', 'ReformerForQuestionAnswering', 'FunnelForQuestionAnswering', 'LxmertForQuestionAnswering', 'MPNetForQuestionAnswering', 'DebertaForQuestionAnswering', 'DebertaV2ForQuestionAnswering', 'IBertForQuestionAnswering', 'SplinterForQuestionAnswering'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LF: Q&A → Similarity Transformer on variable: cat_or_dog\n",
      "4 documents with validations for variable: cat_or_dog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 2/2 [00:00<00:00, 11.18it/s]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s]\n"
     ]
    }
   ],
   "source": [
    "extractor.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LF: Keyword Match\n",
      "Loading Resources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting variable: cat_or_dog: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LF: Q&A → Similarity Transformer\n",
      "Loading Resources.\n",
      "Fine tuning similarity model found, loading...\n",
      "Fine tuned Q&A model found, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'RobertaForQuestionAnsweringWithNegatives' is not supported for question-answering. Supported models are ['QDQBertForQuestionAnswering', 'FNetForQuestionAnswering', 'GPTJForQuestionAnswering', 'LayoutLMv2ForQuestionAnswering', 'RemBertForQuestionAnswering', 'CanineForQuestionAnswering', 'RoFormerForQuestionAnswering', 'BigBirdPegasusForQuestionAnswering', 'BigBirdForQuestionAnswering', 'ConvBertForQuestionAnswering', 'LEDForQuestionAnswering', 'DistilBertForQuestionAnswering', 'AlbertForQuestionAnswering', 'CamembertForQuestionAnswering', 'BartForQuestionAnswering', 'MBartForQuestionAnswering', 'LongformerForQuestionAnswering', 'XLMRobertaForQuestionAnswering', 'RobertaForQuestionAnswering', 'SqueezeBertForQuestionAnswering', 'BertForQuestionAnswering', 'XLNetForQuestionAnsweringSimple', 'FlaubertForQuestionAnsweringSimple', 'MegatronBertForQuestionAnswering', 'MobileBertForQuestionAnswering', 'XLMForQuestionAnsweringSimple', 'ElectraForQuestionAnswering', 'ReformerForQuestionAnswering', 'FunnelForQuestionAnswering', 'LxmertForQuestionAnswering', 'MPNetForQuestionAnswering', 'DebertaForQuestionAnswering', 'DebertaV2ForQuestionAnswering', 'IBertForQuestionAnswering', 'SplinterForQuestionAnswering'].\n",
      "Extracting variable: cat_or_dog: 100%|██████████| 2/2 [00:00<00:00, 13.19it/s]\n"
     ]
    }
   ],
   "source": [
    "extractor.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('elicit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b172029f19524460cce6c4747fdf3f29a8b5708838bec7f17ceb06e5028447e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
