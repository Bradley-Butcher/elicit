{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elicit Basics\n",
    "\n",
    "This example will walk you through the basics of how to:\n",
    "- Create an \"Extractor\", a controller which handles the extraction.\n",
    "- Add required labelling functions and schemas to the extractor.\n",
    "- Run the extraction process.\n",
    "- Launch the user interface to begin annotating the extractions.\n",
    "\n",
    "We will be using the existing Keyword Extractor labelling function as an example.\n",
    "\n",
    "We begin by importing the requirements.\n",
    "\n",
    "## Importing Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/miniconda3/envs/elicit/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/dev/miniconda3/envs/elicit/lib/python3.9/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/dev/Turing/elicit/examples\n",
      "Documents: ['doc_1.txt', 'doc_2.txt']\n"
     ]
    }
   ],
   "source": [
    "# Import Extractor class and launch UI function.\n",
    "from elicit import Extractor, launch_ui\n",
    "# Import the Keyword Match Labelling Function.\n",
    "from elicit.generic_labelling_functions import KeywordMatchLF, NLILabellingFunction\n",
    "# Import Pathlib, for better path handling.\n",
    "from pathlib import Path\n",
    "# Import OS so we know where the notebook is!\n",
    "import os\n",
    "\n",
    "current_path = os.path.abspath('')\n",
    "\n",
    "# get current directory\n",
    "current_dir = Path(current_path)\n",
    "\n",
    "docs = list((current_dir / \"basic_example_docs\").glob(\"*.txt\"))\n",
    "\n",
    "print(\"Current directory:\", current_dir)\n",
    "print(\"Documents:\", [d.name for d in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Extractor\n",
    "\n",
    "Lets first create an Extractor object, pointing at the DB file we want to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Extraction Database: /home/dev/Turing/elicit/examples/test_db.sqlite\n"
     ]
    }
   ],
   "source": [
    "# delete db if already exists (just for testing purposes)\n",
    "(current_dir / \"test_db.sqlite\").unlink(missing_ok=True)\n",
    "\n",
    "extractor = Extractor(db_path=current_dir / \"test_db.sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering Schemas\n",
    "\n",
    "Next, we will add the required schemas. These are the configuration files the labelling functions will use to extract the data.\n",
    "\n",
    "In this case, we require:\n",
    "- A categories schema\n",
    "- A keywords schema\n",
    "\n",
    "Categories is always required. It tells the system what categories each variable has, or whether it is numerical/raw. More details on this in the documentation.\n",
    "\n",
    "Keywords are a dictionary of variable category to keyword list. Each category of a variable will have some user-defined set of keywords.\n",
    "\n",
    "These schemas can either be a Path to a yaml file, or a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered schema: categories\n",
      "Registered schema: keywords\n",
      "Registered schema: questions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categories = {\"cat_or_dog\": [\"cat\", \"dog\"]}\n",
    "keywords = {\"cat_or_dog\": {\"cat\": [\"meow\", \"hiss\"], \"dog\": [\"woof\", \"bark\"]}}\n",
    "\n",
    "extractor.register_schema(schema=categories,\n",
    "                            schema_name=\"categories\")\n",
    "extractor.register_schema(schema=keywords,\n",
    "                            schema_name=\"keywords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering Labelling Functions\n",
    "\n",
    "Next, we register the labelling function. In this case, we have just imported the pre-defined Keyword Extractor labelling function. In a future tutorial, we will create our own labelling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered labelling function: Keyword Match\n",
      "Registered labelling function: Q&A → NLI Transformer\n"
     ]
    }
   ],
   "source": [
    "extractor.register_labelling_function(KeywordMatchLF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the extractor\n",
    "\n",
    "We can now run the extraction process, we pass a list of Paths pointing to each document. Currently PDFs and TXTs are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LF: Keyword Match\n",
      "Loading models and stuff...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting variable: cat_or_dog: 100%|██████████| 2/2 [00:01<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LF: Q&A → NLI Transformer\n",
      "Loading models and stuff...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting variable: cat_or_dog: 100%|██████████| 2/2 [00:00<00:00, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': 'are you a cat?', 'context': 'The cat goes meow.'}, {'question': 'are you a dog?', 'context': 'The cat goes meow.'}]\n",
      "[{'question': 'are you a cat?', 'context': 'The dog goes woof.'}, {'question': 'are you a dog?', 'context': 'The dog goes woof.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extractor.run(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the user interface\n",
    "\n",
    "Finally, we can launch the user interface to begin annotating the extractions, pointing either to a database path, or simply passing in the extractor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Launched UI at: <a href=\"http://localhost:8080\">http://localhost:8080</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UI Killed\n"
     ]
    }
   ],
   "source": [
    "launch_ui(extractor=extractor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('elicit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b172029f19524460cce6c4747fdf3f29a8b5708838bec7f17ceb06e5028447e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
